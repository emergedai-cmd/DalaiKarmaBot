// LM Studio (OpenAI-compatible) provider example for DalaiKarmaBot.
// 1) Start LM Studio server (default http://127.0.0.1:1234)
// 2) Add this under `models.providers.lmstudio` in your config.

{
  lmstudio: {
    baseUrl: "http://127.0.0.1:1234/v1",
    apiKey: "lmstudio",
    api: "openai-responses",
    models: [
      {
        id: "YOUR_MODEL_ID",
        name: "Local LM Studio Model",
        reasoning: false,
        input: ["text"],
        cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
        contextWindow: 8192,
        maxTokens: 2048,
      },
    ],
  },
}
