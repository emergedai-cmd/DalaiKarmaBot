// Ollama provider example for DalaiKarmaBot.
// 1) Ensure Ollama is running (default http://127.0.0.1:11434)
// 2) Pull a model, e.g. `ollama pull llama3.1`
// 3) Add this under `models.providers.ollama` in your config.

{
  ollama: {
    baseUrl: "http://127.0.0.1:11434",
    models: [
      {
        id: "llama3.1",
        name: "Ollama llama3.1",
        input: ["text"],
        cost: { input: 0, output: 0, cacheRead: 0, cacheWrite: 0 },
        contextWindow: 8192,
        maxTokens: 2048,
      },
    ],
  },
}
